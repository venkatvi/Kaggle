This is a code base maintained towards Kaggle 101 Competition:
https://www.kaggle.com/c/titanic-gettingStarted

Strategies followed are explained below:
Submission 1: 
Parse Ticket filed to 2 fields - Ticket Prefix, and Ticket Number
Parse Cabin - seperate Cabin class from number. If multiple cabin numbers present, add new rows for each of them 
use Mean Age, Fare as fillers
use 0 for missing Embarked
use '' for missing cabin class
use -1 for missing cabin number
use 1 for female and 0 for male
map 1 - C, 2- Q , 3 - S for Embarkment
Drop Name field
Random Forest to fit and predict
Prediction Accuracy 0.6406

Submission 2: 
Use graphsearchcv to cross validate data and fit a forest
<Intermediate Submissions - Use median instead of mode> 
Prediction Accuracy 0.66


Submission 3:
Parse Name field to extract "Title" -> map it to 0 - other, 1 - master, 2 - Miss, 3- Mr, 4 - Mrs. 
Drop ticket, cabin and Name fields
Retain gender, age, title, fare, parch, sibsp, pclass and embarked 
Use NaiveBayes in training and test data to predict Age 
Use random forest to predict survived 
Prediction Accuracy 0.56

Submission 4:
Drop ticket, cabin and name fields
Retain title
Use mean age and fare as fillers
Use random forest to predict 
Prediction Accuracy 0.744

Submission 5:
Use median in Submission 4 
Prediction Accuracy 0.741

Submission 6: 
Drop ticket, cabin, age, name, sibsp, parch
Use title (derived from name)
How about gender, title, pclass to predict survival ?
Prediction Accuracy: 0.78468

Submission 7:
Drop pclass . Use only gender and title 
No discrimination on the status
Prediction Accuracy: 0.76077 

Class is a good indicator. 

Submission 8: 
which field is now better? 
gender, title, pclass, sibsp, parch ?
or gender, pclass, sibsp, parch ?
Gives Accuracy: 0.76

Submission 9:
Gender Class 
Gives 0.68 accuracy

Submission 10:
Gender Class Title TicketNumber - give 0.689

Submission 11: 
Gender Class Title Embarked - 0.7849


------- Random forest has been exhausted ------

Other ideas for classification:

1. K-nn approach of giving a label to test data based on its training data neighbours
2. PCA to figure out lower dimension in which this data can be represented
3. Mix of 2, 1 - Pipeline of PCA, K-nn - 

4. Pipeline of PCA (all dimensions) RF
5. Use gridsearchcv for each of these approaches

Class Gender Title has the highest score but still lower than Random forests

--------- Alternate approaches -----------

Use all float fields except Ticket and Cabin
Filled Age and Fare with mean values
Prediction Accuracy - 0.78


Scale them using sklearn preprocessing routine. 

Select features using RandomForestClassifier using cross validation, train test split
With best estimator  - fit transform for train and test

Use those features and predict using SVM 

Score: 0.764 


- remove fare, age, sibsp, parch - Use gender  class title only

Prediction Accuracy is 0.71  

Score: 0.68 

looks like this has a linear prediction compared to actual score. 

Tweaking these values to see if any better results can be obtained. 

No luck on prediction accuracy - hence moving to next strategy

--------------------------------------------------------------------

Iterate over this idea:
	Use random forest - predict using gender, title, class
	Use predicted results along with training set to again train the data using cross validation
	Overfit the test predictions till the predictions saturate. 

	Gradient Descent on unseen data

	See if score improves














